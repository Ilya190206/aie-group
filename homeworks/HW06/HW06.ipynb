{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77559bd3-d113-4ce9-a7ca-a71023a6822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основные библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Установка стиля графиков\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Модели и метрики\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve, auc,\n",
    "    ConfusionMatrixDisplay, PrecisionRecallDisplay, RocCurveDisplay\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Baseline модели\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Модели недели 6\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    AdaBoostClassifier, \n",
    "    GradientBoostingClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "\n",
    "print(\"Библиотеки успешно импортированы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36921c0d-40bf-44ed-97b1-43302e333237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "url = \"https://raw.githubusercontent.com/Ilya190206/aie-group/refs/heads/main/homeworks/HW06/S06-hw-dataset-01.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Данные успешно загружены\")\n",
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"Колонки: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cff7e-5f20-4ddc-9203-bd2e18487eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр первых строк\n",
    "print(\"Первые 5 строк датасета:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Информация о данных:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Статистические характеристики числовых признаков:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Проверка пропусков\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Пропуски в данных:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"Пропусков нет!\")\n",
    "\n",
    "# Распределение целевой переменной\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Распределение целевой переменной (target):\")\n",
    "target_dist = df['target'].value_counts()\n",
    "print(target_dist)\n",
    "print(f\"\\nДоли классов: {target_dist / len(df)}\")\n",
    "\n",
    "# Визуализация распределения таргета\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Гистограмма\n",
    "axes[0].bar(['Class 0', 'Class 1'], target_dist.values, color=['skyblue', 'salmon'])\n",
    "axes[0].set_title('Распределение классов', fontsize=14)\n",
    "axes[0].set_ylabel('Количество')\n",
    "axes[0].set_xlabel('Класс')\n",
    "\n",
    "# Круговая диаграмма\n",
    "axes[1].pie(target_dist.values, labels=['Class 0', 'Class 1'], \n",
    "           autopct='%1.1f%%', colors=['skyblue', 'salmon'])\n",
    "axes[1].set_title('Доли классов', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78d7b9-7a7a-4fca-bec6-dc51521a7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ категориальных признаков\n",
    "cat_features = ['cat_contract', 'cat_region', 'cat_payment']\n",
    "print(\"Анализ категориальных признаков:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for feature in cat_features:\n",
    "    unique_vals = df[feature].unique()\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(f\"  Уникальные значения: {sorted(unique_vals)}\")\n",
    "    print(f\"  Количество уникальных значений: {len(unique_vals)}\")\n",
    "    \n",
    "    # Распределение значений\n",
    "    value_counts = df[feature].value_counts().sort_index()\n",
    "    print(f\"  Распределение: {value_counts.to_dict()}\")\n",
    "    \n",
    "    # Визуализация\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Барплот\n",
    "    axes[0].bar(value_counts.index.astype(str), value_counts.values)\n",
    "    axes[0].set_title(f'Распределение {feature}', fontsize=14)\n",
    "    axes[0].set_xlabel(feature)\n",
    "    axes[0].set_ylabel('Количество')\n",
    "    \n",
    "    # Барплот по классам\n",
    "    cross_tab = pd.crosstab(df[feature], df['target'])\n",
    "    cross_tab.plot(kind='bar', ax=axes[1])\n",
    "    axes[1].set_title(f'{feature} по классам', fontsize=14)\n",
    "    axes[1].set_xlabel(feature)\n",
    "    axes[1].set_ylabel('Количество')\n",
    "    axes[1].legend(['Class 0', 'Class 1'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'artifacts/figures/{feature}_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Анализ числовых признаков\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Анализ числового признака tenure_months:\")\n",
    "print(f\"Минимум: {df['tenure_months'].min()}\")\n",
    "print(f\"Максимум: {df['tenure_months'].max()}\")\n",
    "print(f\"Среднее: {df['tenure_months'].mean():.2f}\")\n",
    "print(f\"Медиана: {df['tenure_months'].median()}\")\n",
    "\n",
    "# Визуализация tenure_months\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Гистограмма\n",
    "axes[0].hist(df['tenure_months'], bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Распределение tenure_months', fontsize=14)\n",
    "axes[0].set_xlabel('tenure_months')\n",
    "axes[0].set_ylabel('Частота')\n",
    "\n",
    "# Боксплот по классам\n",
    "data = [df[df['target'] == 0]['tenure_months'], \n",
    "        df[df['target'] == 1]['tenure_months']]\n",
    "axes[1].boxplot(data, labels=['Class 0', 'Class 1'])\n",
    "axes[1].set_title('tenure_months по классам', fontsize=14)\n",
    "axes[1].set_ylabel('tenure_months')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/tenure_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Корреляционная матрица числовых признаков (первые 10 для наглядности)\n",
    "num_features = [f'num{i:02d}' for i in range(1, 25)] + ['tenure_months']\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df[num_features].corr()\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Корреляционная матрица числовых признаков', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb642a-6abd-42ce-8d5f-3a1cfc67dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание папок для артефактов\n",
    "Path(\"artifacts/figures\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "X = df.drop(['id', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"Размер X: {X.shape}\")\n",
    "print(f\"Размер y: {y.shape}\")\n",
    "print(f\"Признаки: {X.columns.tolist()}\")\n",
    "print(f\"Количество признаков: {len(X.columns)}\")\n",
    "\n",
    "# Разделение на train/test с фиксированным random_state и стратификацией\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Разделение данных:\")\n",
    "print(f\"Размер X_train: {X_train.shape}\")\n",
    "print(f\"Размер X_test: {X_test.shape}\")\n",
    "print(f\"Размер y_train: {y_train.shape}\")\n",
    "print(f\"Размер y_test: {y_test.shape}\")\n",
    "\n",
    "# Проверка распределения классов в train и test\n",
    "print(\"\\nРаспределение классов в train:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nРаспределение классов в test:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "# Обоснование выбора параметров\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Обоснование выбора параметров:\")\n",
    "print(\"1. test_size=0.2: Стандартное значение для сохранения достаточного количества данных для обучения\")\n",
    "print(\"2. random_state=42: Для воспроизводимости результатов\")\n",
    "print(\"3. stratify=y: Для сохранения распределения классов в train и test наборах\")\n",
    "print(\"4. Разделение проводится ДО любых преобразований для избежания data leakage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d05174c-2887-4ae4-999c-ee112f092b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"BASELINE МОДЕЛИ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Dummy Classifier\n",
    "print(\"\\n1. Dummy Classifier (стратегия: most_frequent):\")\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "y_pred_proba_dummy = dummy.predict_proba(X_test)[:, 1]\n",
    "\n",
    "dummy_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_dummy),\n",
    "    'f1': f1_score(y_test, y_pred_dummy),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_dummy)\n",
    "}\n",
    "\n",
    "print(f\"Accuracy: {dummy_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-score: {dummy_metrics['f1']:.4f}\")\n",
    "print(f\"ROC-AUC: {dummy_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# 2. Logistic Regression\n",
    "print(\"\\n2. Logistic Regression с StandardScaler:\")\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "y_pred_lr = lr_pipeline.predict(X_test)\n",
    "y_pred_proba_lr = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lr_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'f1': f1_score(y_test, y_pred_lr),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_lr)\n",
    "}\n",
    "\n",
    "print(f\"Accuracy: {lr_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-score: {lr_metrics['f1']:.4f}\")\n",
    "print(f\"ROC-AUC: {lr_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Сравнение baseline моделей\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"СРАВНЕНИЕ BASELINE МОДЕЛЕЙ\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Dummy', 'Logistic Regression'],\n",
    "    'Accuracy': [dummy_metrics['accuracy'], lr_metrics['accuracy']],\n",
    "    'F1-score': [dummy_metrics['f1'], lr_metrics['f1']],\n",
    "    'ROC-AUC': [dummy_metrics['roc_auc'], lr_metrics['roc_auc']]\n",
    "})\n",
    "\n",
    "display(comparison_df)\n",
    "\n",
    "# Визуализация ROC-кривых для baseline моделей\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Dummy\n",
    "fpr_dummy, tpr_dummy, _ = roc_curve(y_test, y_pred_proba_dummy)\n",
    "roc_auc_dummy = auc(fpr_dummy, tpr_dummy)\n",
    "plt.plot(fpr_dummy, tpr_dummy, label=f'Dummy (AUC = {roc_auc_dummy:.3f})', linestyle='--')\n",
    "\n",
    "# Logistic Regression\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривые: Baseline модели')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig('artifacts/figures/baseline_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nИнтерпретация baseline моделей:\")\n",
    "print(\"1. Dummy Classifier показывает минимально достижимые метрики\")\n",
    "print(\"2. Logistic Regression должен показать лучшие результаты за счет учета взаимосвязей признаков\")\n",
    "print(\"3. ROC-AUC > 0.5 показывает, что модель лучше случайного угадывания\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef3b4c-af6d-4b09-bea4-a235f3f305e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"DECISION TREE CLASSIFIER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Определение параметров для GridSearch\n",
    "dt_param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'ccp_alpha': [0.0, 0.01, 0.1]  # Параметр для cost-complexity pruning\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "print(\"Подбор гиперпараметров через GridSearchCV (5-fold CV)...\")\n",
    "dt_grid = GridSearchCV(\n",
    "    dt, dt_param_grid, \n",
    "    cv=5, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры:\")\n",
    "print(dt_grid.best_params_)\n",
    "print(f\"Лучший CV ROC-AUC: {dt_grid.best_score_:.4f}\")\n",
    "\n",
    "# Обучение лучшей модели\n",
    "best_dt = dt_grid.best_estimator_\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "y_pred_proba_dt = best_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "dt_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_dt),\n",
    "    'f1': f1_score(y_test, y_pred_dt),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_dt),\n",
    "    'best_params': dt_grid.best_params_,\n",
    "    'cv_score': dt_grid.best_score_\n",
    "}\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке:\")\n",
    "print(f\"Accuracy: {dt_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-score: {dt_metrics['f1']:.4f}\")\n",
    "print(f\"ROC-AUC: {dt_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Визуализация дерева (упрощенная версия для лучшего понимания)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_dt, \n",
    "          feature_names=X.columns,\n",
    "          class_names=['Class 0', 'Class 1'],\n",
    "          filled=True, \n",
    "          rounded=True,\n",
    "          max_depth=3,  # Показываем только 3 уровня для читаемости\n",
    "          fontsize=10)\n",
    "plt.title(f'Decision Tree (max_depth={best_dt.max_depth})', fontsize=16)\n",
    "plt.savefig('artifacts/figures/decision_tree_structure.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Анализ важности признаков\n",
    "feature_importance_dt = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_dt.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nТоп-10 важных признаков по Decision Tree:\")\n",
    "display(feature_importance_dt.head(10))\n",
    "\n",
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_features = feature_importance_dt.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Важность признака')\n",
    "plt.title('Важность признаков (Decision Tree)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/dt_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Анализ влияния глубины дерева на качество\n",
    "print(\"\\nАнализ влияния глубины дерева:\")\n",
    "depth_results = []\n",
    "for depth in [1, 2, 3, 5, 7, 10, 15, 20, None]:\n",
    "    dt_temp = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt_temp.fit(X_train, y_train)\n",
    "    train_score = roc_auc_score(y_train, dt_temp.predict_proba(X_train)[:, 1])\n",
    "    test_score = roc_auc_score(y_test, dt_temp.predict_proba(X_test)[:, 1])\n",
    "    depth_results.append({\n",
    "        'max_depth': depth if depth else 'None',\n",
    "        'train_roc_auc': train_score,\n",
    "        'test_roc_auc': test_score\n",
    "    })\n",
    "\n",
    "depth_df = pd.DataFrame(depth_results)\n",
    "print(depth_df)\n",
    "\n",
    "# График зависимости качества от глубины\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depth_df['max_depth'].astype(str), depth_df['train_roc_auc'], \n",
    "         marker='o', label='Train ROC-AUC', linewidth=2)\n",
    "plt.plot(depth_df['max_depth'].astype(str), depth_df['test_roc_auc'], \n",
    "         marker='s', label='Test ROC-AUC', linewidth=2)\n",
    "plt.xlabel('Максимальная глубина дерева')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.title('Зависимость качества от глубины дерева')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/dt_depth_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nВыводы по Decision Tree:\")\n",
    "print(\"1. Дерево показывает склонность к переобучению при большой глубине\")\n",
    "print(\"2. GridSearchCV помог найти оптимальные гиперпараметры\")\n",
    "print(\"3. Важность признаков дает первую интуицию о влиянии разных факторов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21316c61-1433-4cbc-9bb9-f818638a90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Определение параметров для GridSearch\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"Подбор гиперпараметров через GridSearchCV (5-fold CV)...\")\n",
    "rf_grid = GridSearchCV(\n",
    "    rf, rf_param_grid, \n",
    "    cv=5, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры:\")\n",
    "print(rf_grid.best_params_)\n",
    "print(f\"Лучший CV ROC-AUC: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Обучение лучшей модели\n",
    "best_rf = rf_grid.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'f1': f1_score(y_test, y_pred_rf),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_rf),\n",
    "    'best_params': rf_grid.best_params_,\n",
    "    'cv_score': rf_grid.best_score_\n",
    "}\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке:\")\n",
    "print(f\"Accuracy: {rf_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-score: {rf_metrics['f1']:.4f}\")\n",
    "print(f\"ROC-AUC: {rf_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Важность признаков для Random Forest\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nТоп-10 важных признаков по Random Forest:\")\n",
    "display(feature_importance_rf.head(10))\n",
    "\n",
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_features_rf = feature_importance_rf.head(15)\n",
    "plt.barh(range(len(top_features_rf)), top_features_rf['importance'])\n",
    "plt.yticks(range(len(top_features_rf)), top_features_rf['feature'])\n",
    "plt.xlabel('Важность признака')\n",
    "plt.title('Важность признаков (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/rf_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Сравнение с Decision Tree\n",
    "print(\"\\nСравнение важности признаков (Decision Tree vs Random Forest):\")\n",
    "importance_comparison = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'dt_importance': best_dt.feature_importances_,\n",
    "    'rf_importance': best_rf.feature_importances_\n",
    "})\n",
    "importance_comparison['diff'] = abs(importance_comparison['dt_importance'] - importance_comparison['rf_importance'])\n",
    "\n",
    "print(\"\\nПризнаки с наибольшей разницей в важности:\")\n",
    "display(importance_comparison.sort_values('diff', ascending=False).head(10))\n",
    "\n",
    "# Анализ влияния количества деревьев\n",
    "print(\"\\nАнализ влияния количества деревьев на качество Random Forest:\")\n",
    "n_estimators_results = []\n",
    "for n_trees in [10, 20, 50, 100, 200, 300]:\n",
    "    rf_temp = RandomForestClassifier(\n",
    "        n_estimators=n_trees, \n",
    "        max_depth=best_rf.max_depth,\n",
    "        min_samples_leaf=best_rf.min_samples_leaf,\n",
    "        max_features=best_rf.max_features,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_temp.fit(X_train, y_train)\n",
    "    train_score = roc_auc_score(y_train, rf_temp.predict_proba(X_train)[:, 1])\n",
    "    test_score = roc_auc_score(y_test, rf_temp.predict_proba(X_test)[:, 1])\n",
    "    n_estimators_results.append({\n",
    "        'n_estimators': n_trees,\n",
    "        'train_roc_auc': train_score,\n",
    "        'test_roc_auc': test_score\n",
    "    })\n",
    "\n",
    "n_estimators_df = pd.DataFrame(n_estimators_results)\n",
    "print(n_estimators_df)\n",
    "\n",
    "# График зависимости качества от количества деревьев\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_df['n_estimators'], n_estimators_df['train_roc_auc'], \n",
    "         marker='o', label='Train ROC-AUC', linewidth=2)\n",
    "plt.plot(n_estimators_df['n_estimators'], n_estimators_df['test_roc_auc'], \n",
    "         marker='s', label='Test ROC-AUC', linewidth=2)\n",
    "plt.xlabel('Количество деревьев')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.title('Зависимость качества Random Forest от количества деревьев')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/rf_n_estimators_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nВыводы по Random Forest:\")\n",
    "print(\"1. Random Forest показывает лучшую обобщающую способность по сравнению с одним деревом\")\n",
    "print(\"2. Ансамблирование уменьшает variance и улучшает устойчивость к переобучению\")\n",
    "print(\"3. Random Forest дает более стабильные оценки важности признаков\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41d3ea-3939-4a3e-9a13-f2a27d26d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"GRADIENT BOOSTING CLASSIFIER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Определение параметров для GridSearch\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "print(\"Подбор гиперпараметров через GridSearchCV (5-fold CV)...\")\n",
    "gb_grid = GridSearchCV(\n",
    "    gb, gb_param_grid, \n",
    "    cv=5, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры:\")\n",
    "print(gb_grid.best_params_)\n",
    "print(f\"Лучший CV ROC-AUC: {gb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Обучение лучшей модели\n",
    "best_gb = gb_grid.best_estimator_\n",
    "y_pred_gb = best_gb.predict(X_test)\n",
    "y_pred_proba_gb = best_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "gb_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_gb),\n",
    "    'f1': f1_score(y_test, y_pred_gb),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_gb),\n",
    "    'best_params': gb_grid.best_params_,\n",
    "    'cv_score': gb_grid.best_score_\n",
    "}\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке:\")\n",
    "print(f\"Accuracy: {gb_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-score: {gb_metrics['f1']:.4f}\")\n",
    "print(f\"ROC-AUC: {gb_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Важность признаков для Gradient Boosting\n",
    "feature_importance_gb = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_gb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nТоп-10 важных признаков по Gradient Boosting:\")\n",
    "display(feature_importance_gb.head(10))\n",
    "\n",
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_features_gb = feature_importance_gb.head(15)\n",
    "plt.barh(range(len(top_features_gb)), top_features_gb['importance'])\n",
    "plt.yticks(range(len(top_features_gb)), top_features_gb['feature'])\n",
    "plt.xlabel('Важность признака')\n",
    "plt.title('Важность признаков (Gradient Boosting)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/gb_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Learning curve для Gradient Boosting\n",
    "print(\"\\nАнализ кривой обучения Gradient Boosting:\")\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for size in train_sizes:\n",
    "    n_samples = int(size * len(X_train))\n",
    "    X_train_subset = X_train.iloc[:n_samples]\n",
    "    y_train_subset = y_train.iloc[:n_samples]\n",
    "    \n",
    "    gb_temp = GradientBoostingClassifier(\n",
    "        n_estimators=best_gb.n_estimators,\n",
    "        learning_rate=best_gb.learning_rate,\n",
    "        max_depth=best_gb.max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    gb_temp.fit(X_train_subset, y_train_subset)\n",
    "    \n",
    "    train_score = roc_auc_score(y_train_subset, gb_temp.predict_proba(X_train_subset)[:, 1])\n",
    "    test_score = roc_auc_score(y_test, gb_temp.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "# График кривой обучения\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes * len(X_train), train_scores, marker='o', label='Train ROC-AUC', linewidth=2)\n",
    "plt.plot(train_sizes * len(X_train), test_scores, marker='s', label='Test ROC-AUC', linewidth=2)\n",
    "plt.xlabel('Размер обучающей выборки')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.title('Кривая обучения Gradient Boosting')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/gb_learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nВыводы по Gradient Boosting:\")\n",
    "print(\"1. Gradient Boosting часто показывает лучшие результаты за счет последовательного улучшения\")\n",
    "print(\"2. Boosting хорошо справляется со сложными нелинейными зависимостями\")\n",
    "print(\"3. Требует тщательного подбора learning rate и других гиперпараметров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f153a4a-92e0-43ff-8d43-40a2bc41f8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
