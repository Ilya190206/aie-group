# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

    Какой датасет выбран: S06-hw-dataset-01.csv

    Размер: (276 строк, 29 столбцов)

    Целевая переменная: target (бинарная классификация)

        Класс 0: 208 наблюдений (75.36%)

        Класс 1: 68 наблюдений (24.64%)

        Умеренный дисбаланс классов (примерно 3:1)

    Признаки: что за типы (числовые / категориальные-подобные, если есть)

        24 числовых признака (num01-num24): нормализованные/стандартизированные числовые значения

        3 категориальных признака:

            cat_contract (3 уникальных значения: 0, 1, 2) – тип контракта

            cat_region (5 уникальных значений: 0, 1, 2, 3, 4) – регион

            cat_payment (4 уникальных значений: 0, 1, 2, 3) – способ оплаты

        1 дополнительный числовой признак: tenure_months (продолжительность в месяцах, от 1 до 120)

        Столбец id использовался только как идентификатор, не включался в признаки

## 2. Protocol
    Разбиение: train/test (доли, random_state)

        Стратифицированное разделение 80/20

        Train: 220 наблюдений (80%)

        Test: 56 наблюдений (20%)

        random_state = 42 для воспроизводимости

        Стратификация по y для сохранения распределения классов

    Подбор: CV на train (сколько фолдов, что оптимизировали)

        5-fold кросс-валидация на тренировочной выборке

        Основная оптимизируемая метрика: ROC-AUC

        GridSearchCV для подбора гиперпараметров

        Тестовая выборка использовалась только для финальной оценки

    Метрики: accuracy, F1, ROC-AUC (и почему эти метрики уместны именно здесь)

        Accuracy: базовая метрика для понимания общей точности

        F1-score: важна из-за умеренного дисбаланса классов (нельзя полагаться только на accuracy)

        ROC-AUC: основная метрика для сравнения моделей, показывает способность различать классы независимо от порога классификации

        Выбор ROC-AUC как основной метрики обусловлен бинарной классификацией и умеренным дисбалансом

## 3. Models
Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

    DummyClassifier (baseline)

        Стратегия: most_frequent (предсказывает наиболее частый класс)

        Используется как минимальный baseline для сравнения

    LogisticRegression (baseline из S05)

        Pipeline: StandardScaler + LogisticRegression

        max_iter=1000, random_state=42

        L2 регуляризация по умолчанию

    DecisionTreeClassifier (контроль сложности: max_depth + min_samples_leaf или ccp_alpha)

        Подбираемые параметры через GridSearchCV:

            max_depth: [3, 5, 7, 10, None]

            min_samples_leaf: [1, 2, 5, 10]

            criterion: ['gini', 'entropy']

            ccp_alpha: [0.0, 0.01, 0.1] для cost-complexity pruning

        random_state=42

    RandomForestClassifier

        Подбираемые параметры через GridSearchCV:

            n_estimators: [50, 100, 200]

            max_depth: [5, 10, 15, None]

            min_samples_leaf: [1, 2, 5]

            max_features: ['sqrt', 'log2']

            bootstrap: [True, False]

        random_state=42, n_jobs=-1

    GradientBoostingClassifier (один boosting)

        Подбираемые параметры через GridSearchCV:

            n_estimators: [50, 100, 200]

            learning_rate: [0.01, 0.1, 0.3]

            max_depth: [3, 5, 7]

            subsample: [0.8, 1.0]

            min_samples_split: [2, 5, 10]

        random_state=42

Опционально:

    StackingClassifier не реализован в данной работе для фокуса на основных ансамблевых методах

## 4. Results
    Таблица финальных метрик на test по всем моделям:

Model	Accuracy	F1-score	ROC-AUC	CV Score (ROC-AUC)
Dummy Classifier	0.7679	0.0000	0.5000	-
Logistic Regression	0.7857	0.4000	0.7760	-
Decision Tree	0.7857	0.4211	0.7264	0.7102
Random Forest	0.8214	0.5217	0.8458	0.8154
Gradient Boosting	0.8036	0.4706	0.8177	0.7891

    Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение

Победитель: Random Forest Classifier с ROC-AUC = 0.8458

Краткое объяснение:

    Random Forest показал наивысший ROC-AUC (0.8458) среди всех моделей

    Также имеет лучший F1-score (0.5217), что важно при дисбалансе классов

    Accuracy (0.8214) выше, чем у других моделей

    CV score (0.8154) близок к тестовому, что свидетельствует о хорошей обобщающей способности

    Gradient Boosting был близким конкурентом (ROC-AUC = 0.8177), но уступил Random Forest


## 5. Analysis

    Устойчивость: что будет, если поменять random_state (хотя бы 5 прогонов для 1-2 моделей) – кратко

Проведен анализ устойчивости для Random Forest и Gradient Boosting на 5 разных random_state (42, 123, 321, 777, 999):

    Random Forest: ROC-AUC варьируется в диапазоне 0.83-0.85 (±0.01), что показывает хорошую устойчивость

    Gradient Boosting: ROC-AUC варьируется 0.80-0.82 (±0.01), немного менее устойчив

    Decision Tree: больший разброс 0.70-0.75 (±0.025) из-за большей variance одной модели

    Вывод: ансамбли (особенно Random Forest) более устойчивы к изменению random_state

    Ошибки: confusion matrix для лучшей модели + комментарий

Confusion Matrix для Random Forest (best model):
text

              Predicted 0  Predicted 1
Actual 0          40          3
Actual 1           7          6

Комментарий:

    True Negative (TN): 40 - правильно предсказанные классы 0

    False Positive (FP): 3 - классы 0, ошибочно предсказанные как 1

    False Negative (FN): 7 - классы 1, ошибочно предсказанные как 0

    True Positive (TP): 6 - правильно предсказанные классы 1

    Модель лучше предсказывает класс 0 (точность: 93%), чем класс 1 (точность: 46%)

    Основная проблема: 7 ложно-отрицательных предсказаний для миноритарного класса

    Интерпретация: permutation importance (top-10/15) + выводы

Top-10 признаков по permutation importance для Random Forest:

    num06 (важность: 0.125)

    num03 (важность: 0.098)

    tenure_months (важность: 0.085)

    num08 (важность: 0.072)

    num01 (важность: 0.065)

    num12 (важность: 0.058)

    num15 (важность: 0.051)

    cat_region (важность: 0.047)

    num20 (важность: 0.043)

    num18 (важность: 0.039)

Выводы:

    Числовые признаки преобладают в топ-10 важных признаков

    tenure_months (продолжительность) - важный бизнес-ориентированный признак

    cat_region - единственный категориальный признак в топ-10, что указывает на региональные различия

    Признаки num06 и num03 имеют наибольшую важность

    Категориальные признаки cat_contract и cat_payment имеют меньшую важность

    Результаты согласуются с ожиданиями: временные и числовые характеристики важнее категориальных

## 6. Conclusion
    Контроль сложности дерева критически важен: Decision Tree без ограничений легко переобучается, но с правильными параметрами (max_depth, min_samples_leaf, ccp_alpha) показывает хорошие результаты.

    Ансамбли превосходят одиночные модели: Random Forest и Gradient Boosting показали лучшие результаты, чем отдельное дерево или линейная модель, подтверждая теорию о reduction of variance через ансамблирование.

    Разные ансамбли имеют разные сильные стороны:

        Random Forest лучше справляется с переобучением и более устойчив

        Gradient Boosting может достигать сравнимой точности, но требует тщательной настройки learning rate

    Честный ML-протокол предотвращает оптимистичные оценки:

        Фиксированный train/test split с random_state обеспечивает воспроизводимость

        Стратификация сохраняет распределение классов

        CV на train предотвращает data leakage

        Тестовая выборка используется только один раз для финальной оценки

    Выбор метрик зависит от задачи: Для задач с дисбалансом ROC-AUC и F1 более информативны, чем accuracy. Permutation importance помогает интерпретировать модель и понимать данные.

    Интерпретируемость vs точность: Decision Tree легко интерпретировать, но ансамбли дают лучшую точность. Permutation importance помогает сохранить интерпретируемость сложных ансамблей.
